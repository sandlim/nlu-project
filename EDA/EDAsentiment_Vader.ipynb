{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./data/train_stories.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk import tokenize\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import subjectivity\n",
    "from nltk.sentiment import SentimentAnalyzer\n",
    "from nltk.sentiment.util import *\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = df[\"sentence1\"]\n",
    "sentence2 = df[\"sentence2\"]\n",
    "sentence3 = df[\"sentence3\"]\n",
    "sentence4 = df[\"sentence4\"]\n",
    "sentence5 = df[\"sentence5\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyseAll(df):\n",
    "    n_sentences, _ = df.shape\n",
    "    scores = np.zeros((n_sentences, 5, 4))\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    for i in range(5):\n",
    "        sentences = df[\"sentence%d\" %(i+1)]\n",
    "        for j in range(len(sentences)):\n",
    "            ss = sid.polarity_scores(sentences[j])\n",
    "            scores[j,i,0] =ss['compound']\n",
    "            scores[j,i,1] =ss['neg']\n",
    "            scores[j,i,2] =ss['neu']\n",
    "            scores[j,i,3] =ss['pos']\n",
    "    return scores\n",
    "        \n",
    "scores = analyseAll(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores[:5000,:,:].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotScoresAsLines(scores):\n",
    "    n,m,l = scores.shape\n",
    "    fig1, ax1 = plt.subplots()\n",
    "    fig2, ax2 = plt.subplots()\n",
    "    fig3, ax3 = plt.subplots()\n",
    "    for i in range(1):\n",
    "        for j in range(200):\n",
    "            score = scores[j,:,i]\n",
    "            maxdeviation = np.max(abs(np.diff(score)))\n",
    "            if maxdeviation > 0.66:\n",
    "                ax1.plot(score)\n",
    "                continue\n",
    "            if maxdeviation > 0.33:\n",
    "                ax2.plot(score)                    \n",
    "                continue\n",
    "            if maxdeviation < 0.33:\n",
    "                ax3.plot(score)   \n",
    "    plt.show()\n",
    "    \n",
    "plotScoresAsLines(scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('scores.csv',scores.reshape(scores.shape[0],scores.shape[1]*scores.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()\n",
    "for sentence in sentence1:\n",
    "    ss = sid.polarity_scores(sentence)\n",
    "    results.append(ss)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in sentence2:\n",
    "    print(sentence)\n",
    "    ss = sid.polarity_scores(sentence)\n",
    "    for k in sorted(ss):\n",
    "        print('{0}: {1}, '.format(k, ss[k]), end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in sentence3:\n",
    "    print(sentence)\n",
    "    ss = sid.polarity_scores(sentence)\n",
    "    for k in sorted(ss):\n",
    "        print('{0}: {1}, '.format(k, ss[k]), end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in sentence4:\n",
    "    print(sentence)\n",
    "    ss = sid.polarity_scores(sentence)\n",
    "    for k in sorted(ss):\n",
    "        print('{0}: {1}, '.format(k, ss[k]), end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in sentence5:\n",
    "    print(sentence)\n",
    "    ss = sid.polarity_scores(sentence)\n",
    "    for k in sorted(ss):\n",
    "        print('{0}: {1}, '.format(k, ss[k]), end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyzeStory():\n",
    "    tknzr = nltk.TweetTokenizer()\n",
    "    for i in range(20):\n",
    "        data = df.loc[i]\n",
    "        matrix = generateMatrix(data)\n",
    "        plt.matshow(matrix)\n",
    "        plt.colorbar()\n",
    "    \n",
    "        \n",
    "def generateMatrix(data):\n",
    "    n_sentences = 6\n",
    "    matrix = np.zeros((n_sentences,n_sentences))\n",
    "    for i in range(n_sentences):\n",
    "        sentence1 = data[i+1]\n",
    "        tokens1 = tknzr.tokenize(sentence1)\n",
    "        normalized_tokens1 = []\n",
    "        for token in tokens1:\n",
    "            normalized_tokens1.append(WordNetLemmatizer().lemmatize(token,'v'))\n",
    "            \n",
    "        for j in range(i+1,n_sentences):\n",
    "            sentence2 = data[j+1]\n",
    "            tokens2 = tknzr.tokenize(sentence2)\n",
    "            normalized_tokens2 = []\n",
    "            for token in tokens2:\n",
    "                normalized_tokens2.append(WordNetLemmatizer().lemmatize(token,'v'))\n",
    "            matrix[i,j] = sentencePairScore(normalized_tokens1,normalized_tokens2)\n",
    "    return matrix\n",
    "            \n",
    "#        print(tokens)\n",
    "#        print(normalized_tokens)    \n",
    "\n",
    "def sentencePairScore(sentence1, sentence2):\n",
    "    value = 0\n",
    "    for word1 in sentence1:\n",
    "        for word2 in sentence2:\n",
    "            if word1 == word2:\n",
    "                value += 1\n",
    "    return value\n",
    "        \n",
    "        \n",
    "analyzeStory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "words = ['gave','went','going','dating']\n",
    "for word in words:\n",
    "    print(word+\"-->\"+WordNetLemmatizer().lemmatize(word,'v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tknzr = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
